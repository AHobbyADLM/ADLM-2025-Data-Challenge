<h1>
    LabDocs Unlocked: An AI Challenge<br>
</h1>
<h3>
    <span style="color:gray"><i>The 2025 ADLM Data Analytics Competition</i></span>
</h3>
<p>
    The Fourth Annual ADLM Data Analytics Competition,invites competitors to improve how laboratory documentation is accessed and utilized. Laboratories generate vast amounts of documentation, ranging from protocols and package inserts to regulatory materials like 510K clearance documents and checklists. These critical resources often require significant time and effort to navigate, presenting a challenge for efficient decision-making and compliance management. This yearâ€™s competition seeks to address this gap by leveraging the power of AI to create a tool capable of quickly and accurately extracting and presenting user-requested information from these complex document stores. The proposed solution would ensure that laboratory professionals can focus on impactful work rather than time-intensive document searches. By fostering innovation in this domain, the competition aims to set new standards in laboratory information management.
</p>

<h2> 
    The Challenge
</h2>
<h3>
    <span style="color:gray"><i>Develop a Tool for Extracting Information from Laboratory Document Stores</i></span>
</h3>
<p>
    This year's competition aims to develop an AI tool to make looking up information in laboratory documentation faster and more efficient. 
    Competitors will be provided with a set of representative documents (protocols, package inserts, 510K clearance documents, regulatory checklists). The challenge is to create a tool that can ingest these documents, then extract and present information from those documents at the user's request. Teams will participate in a preliminary competition where they will be scored based on the quality and performance of their solution. The top two teams will have the opportunity to present their build in a Webinar where a champion will be crowned in a live head-to-head competition. 
</p>

<h2>Preliminary competition and scoring</h2>
<p>
   Competitors will login to a web application where they will be presented a series of questions that are answerable using the information contained in the documents provided. They will earn points based on the accuracy and speed of their answers. They will also be required to submit their code which will be scored based on the following criteria:
</p>

<h3>User experience (xx points)</h3>
<p>
    An optimal tool would be intuitive and interactive, allowing users to easily navigate and interact with the tool. 
</p>
<h3>Explainability (xx points)</h3>
<p>An optimal solution would provide references or links to relevant sections the document store to improve user confidence and facilitate additional document exploration.</p>
<h3>
    Best  practices (xx points)
</h3>
<p>
    Best practices in software development help to optimize quality, maintainability, and reusability. 
    Note that source code and commit histories are required to be eligible for points in this section.
</p>
<dl>
    <dt>
        Readability (4 points)
    </dt>
    <dd>
        Code is clearly and cleanly commented (1 point)<br>
        Code is simple and not bloated (1 point)<br>
        Code utilizes a clear and consistent naming convention (1 point)<br>
        Code is organized into hierarchy of modular functional units (1 point)
    </dd>
    <dt>
        Reusability (2 points)
    </dt>
    <dd>
        Code utilizes functionalized or object oriented programming (1 point)<br>
        Code can be repurposed to ingest a new document store without modification of source code (1 point)<br>
    </dd>
    <dt>
        Version control (2 points)
    </dt>
    <dd>
        Version control system used to track development (1 point)<br>
        Commits are modular, logical, and appropriately scoped (1 point)
    </dd>
    <dt>
        Documentation and deployment (4 points)
    </dt>
    <dd>
        Usage notes provided (1 point)<br>
        Dependencies are defined (1 point)<br>
        Virtualized or containerized environment used (1 point)<br>
        Tool accessible through web hosting (1 point)
    </dd>
</dl>
<h2>
    Final (live) competition
</h2>
<p>
    The top two teams from the preliminary competition will be invited to present their solution in a live Webinar/competition event. The teams will be judged on the speed and accuracy of their responses to a new set of questions presented "game show style". The team with the highest score will be declared the winner.
</p>

<h2>
    Significance
</h2>
<p>
    Efficient access to laboratory documentation is essential for maintaining compliance, ensuring quality, and accelerating decision-making. This challenge addresses the inefficiencies caused by the complexity and volume of such documents by leveraging AI to streamline information retrieval. The resulting tool has the potential to transform workflows, reduce errors, and set a new standard for document management in laboratory practice.
</p>

<h2>
    Timeline
</h2>

<table>
    <tr>
        <th>
            July 21<sup>st</sup>, 2025
        </th>
        <td>
            Competition Begins
        </td>
    </tr>
    <tr>
        <th>
            November 15<sup>st</sup>, 2025
        </th>
        <td>
            Competition Ends
        </td>
    </tr>
    <tr>
        <th>
            December 15<sup>th</sup>, 2025
        </th>
        <td>
            Announcement of Winning Team
        </td>
    </tr>
    <tr>
        <th>
            January, 2026 (Anticipated)
        </th>
        <td>
            Finalist Prentation and Competition Webinar
        </td>
    </tr>
</table>

<h2>
    How to Participate
</h2>

<h3>
    Sign up for a GitHub.com account
</h3>
<ol>
    <li>
        Navigate to <a href='https://github.com/'>https://github.com</a>
    </li>
    <li>
        Click 'Sign up'
    </li>
    <li>
        Follow the prompts to create your personal account
    </li>
</ol>

<h3>
    Fork the competition repository
</h3>
<dl>
<ol>
    <li>
        Navigate to <a href='https://github.com/WUSM-LGM-Informatics-Section/2025_ADLM_Data_Analytics_Challenge'>https://github.com/WUSM-LGM-Informatics-Section/2025_ADLM_Data_Analytics_Challenge </a>
    </li>
    <li>
        Click 'Fork'
    </li>
    <li>
        Select 'Create a new fork'
    </li>
    <li>
        Set your GitHub account as the owner (default)
    </li>
    <li>
        Click 'Create fork'
    </li>
</ol>

<h3>
    Build your solution
</h3>
<ol>
    <li>
        Clone the forked repository<br>
        <span style='background-color:lightgray;padding:5px;border-radius:10px'>
            git clone https://github.com/WUSM-LGM-Informatics-Section/2025_ADLM_Data_Analytics_Challenge
        </span><br>
        Note: Replace myGitHubUsername with your GitHub handle
    </li>
    <li>
        Make a folder in the cloned repository with your team name
    </li>
    <li>
        Build your solution within your team folder
    </li>
</ol>

<h3>
    Submit your solution via a pull request
</h3>
<ol>
    <li>
        Navigate to <a href='https://github.com/WUSM-LGM-Informatics-Section/2025_ADLM_Data_Analytics_Challenge'>https://github.com/WUSM-LGM-Informatics-Section/2025_ADLM_Data_Analytics_Challenge</a><br>
        Note: Replace myGitHubUsername with your GitHub handle
    </li>
    <li>
        Click 'Contribute'
    </li>
    <li>
        Select 'Open pull request'<br>
    </li>
    <li>
        Click 'Create pull request'
    </li>
    Note: we will review your pull request to ensure that it contain everything needed to score your submission<br>
    <u><strong>Important: You must submit your solution by May 15th, 2024 to be eligible to win the competition</strong></u>
    </li>
</ol>

<h2>
    Need Help?
</h2>
<p>
    If you are unfamiliar with GitHub, need help getting starting, or have other questions, please email mboyle@myadlm.org for assistance.
</p>

<h2>
    Reference
</h2>
<ol style="line-spacing:4">

</ol>
